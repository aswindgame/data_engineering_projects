{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDKzLXTjOMEyCAgcXIX9Dw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"l1Zr96QY1Reg","executionInfo":{"status":"ok","timestamp":1743141576355,"user_tz":-330,"elapsed":5785,"user":{"displayName":"Mugundan Aswin","userId":"03807238789660081623"}}},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI(\n","  base_url=\"OpenAI_base_URL\",\n","  api_key=\"api_key\",\n",")\n","\n","# Below codes in this cell is to test the AI connection \n","# job_description = \"\"\"\n","# We are looking for a Senior Data Engineer with experience in building and maintaining scalable data pipelines.\n","# The ideal candidate should be proficient in Python, SQL, and have experience with cloud platforms such as AWS or Azure.\n","# Familiarity with Apache Spark, Databricks, and ETL frameworks is required.\n","# Strong knowledge of data modeling, data warehousing, and working with REST APIs is a plus.\n","# \"\"\"\n","\n","# # # Call the OpenAI API\n","# response = client.chat.completions.create(\n","#   model=\"gpt-3.5-turbo\",\n","#   messages=[\n","#     {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts technical skills as comma separated list from job descriptions.\"},\n","#     {\"role\": \"user\", \"content\": job_description}\n","#   ]\n","# )\n","# print(response.choices[0].message.content)\n","# O/P: Python, SQL, AWS, Azure, Apache Spark, Databricks, ETL frameworks, data modeling, data warehousing, REST APIs\n","\n"]},{"cell_type":"code","source":["!pip install selenium\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","import time\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.common.keys import Keys\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.common.exceptions import TimeoutException\n","from collections import Counter\n","\n","# Function to scrape LinkedIn job postings and extract skills\n","def scrape_linkedin_jobs(keyword, num_pages):\n","    job_skills = []\n","\n","    # Set up options for the Chrome WebDriver\n","    options = webdriver.ChromeOptions()\n","    options.add_argument('--headless')  # Run Chrome in headless mode (optional)\n","    options.add_argument(\"--no-sandbox\")\n","\n","    # Start a Selenium WebDriver with options\n","    driver = webdriver.Chrome(options=options)\n","\n","\n","    url = f'https://www.linkedin.com/jobs/search/?keywords={keyword}&location=Germany'\n","    driver.get(url)\n","    j = 0\n","    # Scroll to load more jobs (you may need to adjust the number of scrolls)\n","    for _ in range(num_pages):\n","        print(\"scroll ######\",j)\n","        j = j+1\n","        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n","        time.sleep(2)  # Wait for content to load\n","\n","    # Extract job titles and skills (modify as needed)\n","    job_cards = driver.find_elements(By.CSS_SELECTOR, '.base-card')\n","    break_element = 0\n","    with open(\"jd.tsv\", mode=\"wt\") as f:\n","      f.write(\"Job_title|Link|Skills|Exp|Visa_status\\n\")\n","      for card in job_cards:\n","        try:\n","          job_title_element = WebDriverWait(card, 10)\\\n","          .until(EC.presence_of_element_located((By.CSS_SELECTOR, '.base-search-card__title')))\n","          company_element = WebDriverWait(card, 10)\\\n","          .until(EC.presence_of_element_located((By.CSS_SELECTOR, '.base-search-card__subtitle')))\n","          description = WebDriverWait(card, 10)\\\n","          .until(EC.presence_of_element_located((By.CSS_SELECTOR, '.base-card__full-link')))\n","\n","          company_name = company_element.text\n","          job_title = job_title_element.text\n","          print(job_title, \" \", company_name)\n","          job_link = description.get_attribute('href')\n","          print(job_link)\n","\n","          #Hitting each job's URL to get more information\n","          job_driver = webdriver.Chrome(options=options)\n","          job_driver.get(job_link)\n","\n","          #expand descriptions by clicking on show more\n","          expand_description(job_driver)\n","          #extract description element\n","          job_description = extract_job_description(job_driver)\n","          #extract skills from description\n","          extracted_skills = extract_skills(job_description)\n","          job_skills.append(extracted_skills)\n","          #Create a CSV file with job details\n","          experience = exp_extract(job_description)\n","          visa_stat = visa_support_check(job_description)\n","          f.write(f\"{job_title}|{job_link}|{str(extracted_skills)}|{experience}|{visa_stat}\\n\")\n","          job_driver.quit()\n","\n","        except Exception as e:\n","          # print(\"Job details not found for this card.\")\n","          print(f\"Error is {e}\")\n","          continue\n","\n","    # Close the WebDriver when done\n","    driver.quit()\n","\n","    #print(job_skills)\n","\n","    return job_skills\n","\n","\n","# Function to extract job description using JavaScript\n","def extract_job_description(driver):\n","    try:\n","        # Wait for the job description element to be present (you can adjust the timeout)\n","        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '.description')))\n","\n","        # Execute JavaScript code to extract job description\n","        job_description = driver.execute_script(\"return document.querySelector('.description').textContent\")\n","        return job_description\n","    except TimeoutException:\n","        return \"Job description not found or couldn't be loaded\"\n","\n","# Function to expand job description by clicking \"show more\" if available\n","def expand_description(driver):\n","    try:\n","        show_more_button = WebDriverWait(card, 10)\\\n","            .until(EC.presence_of_element_located((By.CSS_SELECTOR, '.show-more-less-html__button')))\n","\n","        show_more_button.click()\n","        time.sleep(2)  # Wait for the description to expand\n","    except Exception as e:\n","        pass  # No \"show more\" button found or error occurred\n","\n","\n","# Function to extract skills from a job title\n","def extract_skills(description):\n","    description = description.lower()\n","    response = client.chat.completions.create(\n","        model=\"deepseek/deepseek-r1:free\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts technical skills as comma separated list from job descriptions.\"},\n","            {\"role\": \"user\", \"content\": description}\n","            ]\n","        )\n","    skills_list = [skill.strip() for skill in response.choices[0].message.content.split(\",\")]\n","    print(skills_list)\n","    return skills_list\n","\n","# Function to find the year of experience needed\n","def exp_extract(description):\n","  description = description.lower()\n","  response = client.chat.completions.create(\n","      model=\"deepseek/deepseek-r1:free\",\n","      messages=[\n","          {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts minimum experience needed for this role from job descriptions and gives output as integer\"},\n","          {\"role\": \"user\", \"content\": description}\n","          ]\n","      )\n","  return response.choices[0].message.content\n","\n","# Function to find whether company helps with visa support\n","def visa_support_check(description):\n","  description = description.lower()\n","  response = client.chat.completions.create(\n","      model=\"deepseek/deepseek-r1:free\",\n","      messages=[\n","          {\"role\": \"system\", \"content\": \"Analyze the given job description and determine whether the organization offers assistance with obtaining a visa. Respond with only 'Yes' or 'No'.\"},\n","          {\"role\": \"user\", \"content\": description}\n","          ]\n","      )\n","  return response.choices[0].message.content\n","\n","# Main function\n","if __name__ == \"__main__\":\n","    keyword = \"data%20engineer\"\n","    num_pages = 15 # You can adjust the number of pages to scrape\n","\n","    job_skills = scrape_linkedin_jobs(keyword, num_pages)\n","\n","    print(f'Data engineer jobs: {len(job_skills)}')\n","\n","    flattened_skills = [skill for sublist in job_skills for skill in sublist]\n","    skill_counts = Counter(flattened_skills)\n","    top_skills = skill_counts.most_common(30)\n","    with open(\"Skill_list.csv\", mode=\"wt\") as f:\n","      f.write(\"Skill_name,Number_of_openings\\n\")\n","      for skill, count in top_skills:\n","        f.write(f\"{skill},{count}\\n\")\n","          # print(f'{skill}: {count}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xGgsaDl1YEm","executionInfo":{"status":"ok","timestamp":1743143880795,"user_tz":-330,"elapsed":2304438,"user":{"displayName":"Mugundan Aswin","userId":"03807238789660081623"}},"outputId":"6fa08836-bf6c-4622-9c77-df12febf57cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.30.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Downloading selenium-4.30.0-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 selenium-4.30.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n","scroll ###### 0\n","scroll ###### 1\n","scroll ###### 2\n","scroll ###### 3\n","scroll ###### 4\n","scroll ###### 5\n","scroll ###### 6\n","scroll ###### 7\n","scroll ###### 8\n","scroll ###### 9\n","scroll ###### 10\n","scroll ###### 11\n","scroll ###### 12\n","scroll ###### 13\n","scroll ###### 14\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-python-and-databricks-at-trinetix-4190274946?position=1&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=YEBe6%2B35GB9OaBU6u2jYxQ%3D%3D\n","['Python', 'Databricks', 'Spark', 'SQL', 'Delta Lake', 'Azure', 'AWS', 'GCP', 'pandas', 'numpy', 'Agile methodologies (Scrum/Kanban)', 'vector databases', 'machine learning', 'NLP', 'AI/LLM integration', 'OpenAI GPT', 'Azure OpenAI', 'Retrieval-Augmented Generation (RAG)', 'NoSQL databases', 'ML Flow', 'Snowflake', 'Redshift', 'Hadoop', 'Kafka', 'ETL', 'big data optimization']\n","Error is invalid literal for int() with base 10: '**Answer:** 2\\n\\nThe job description specifies a minimum of 2+ years of experience with Python and 1+ years with Databricks. Since the role prioritizes Python proficiency and the highest explicit req\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-at-sr2-socially-responsible-recruitment-certified-b-corporation%E2%84%A2-4189913255?position=2&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=5MRYR2YTnIqAsahLgJ%2FSiw%3D%3D\n","['Python', 'SQL', 'Power BI', 'Tableau']\n","   \n","https://de.linkedin.com/jobs/view/data-ai-engineer-frankfurt-cologne-stuttgart-germany-at-unit8-4184400297?position=3&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=CuInpOahN96ZOIFyDsPPoQ%3D%3D\n","['Python', 'Scala', 'Java', 'AWS', 'Azure', 'Docker', 'Kubernetes (EKS)', 'CloudFormation', 'Databricks', 'Apache Spark', 'PySpark', 'ML Studio', 'Data Factory', 'CI/CD', 'Data Engineering', 'ETL (Extract-Transform-Load)', 'Machine Learning', 'Statistical Methods', 'MLOps', 'Data Lake', 'Data Science Platforms', 'Cloud Infrastructure', 'Software Engineering', 'Real-time Monitoring Systems', 'Data Analytics', 'AI', 'Cloud Technologies', 'Data Processing', 'Presentation/Communication Skills']\n","   \n","https://de.linkedin.com/jobs/view/associate-data-engineer-f-m-d-at-imago-4192792520?position=4&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=J8EWKWfVahhdqcL8EYOn%2FQ%3D%3D\n","['Microsoft SQL Server', 'SQL', 'SQL Server Integration Services (SSIS)', 'Python', 'dbt (data build tool)', 'Orchestration frameworks', 'Cloud Data Warehouse (DWH) solutions', 'Tableau', 'Tableau Server', 'PowerShell', 'Data modeling', 'Data warehouse design', 'NoSQL', 'Apache Spark', 'Apache Hive', 'Hadoop', 'Infrastructure as Code (IaC)', 'Terraform', 'Ansible', 'CI/CD pipelines', 'ETL processes.']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-bi-analyst-at-huk-coburg-4157240656?position=5&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=FGzm8%2FFEmHlFzO9aS4j7NA%3D%3D\n","['MS Power BI', 'Tableau', 'QlikView', 'SQL', 'databases', 'ETL processes', 'data analysis', 'data modeling', 'data visualization', 'agile methodologies']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-akeno-4190289090?position=6&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=hChtaajC2UzHGUT%2BE4sbhA%3D%3D\n","['Python', 'SQL', 'Databricks', 'Azure Data Factory', 'Jupyter Notebooks', 'data pipeline design', 'stream architecture', 'MLops', 'machine learning', 'mathematical optimization', 'infrastructure deployment', 'data orchestration', 'experiment analytics.']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-f-m-d-at-imago-4192791503?position=7&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=jFLBUitCRgztL5SP%2BWCeIw%3D%3D\n","['Microsoft SQL Server Integration Services (SSIS)', 'SQL', 'ETL pipelines', 'Python', 'dbt (Data Build Tool)', 'orchestration frameworks', 'cloud data warehouse solutions (Snowflake', 'BigQuery)', 'Tableau', 'PowerShell', 'data modeling', 'data warehouse architecture', 'NoSQL databases', 'Hadoop', 'Apache Spark', 'Hive', 'infrastructure as code (Terraform', 'Ansible)', 'data quality checks', 'performance tuning', 'data documentation']\n","Error is invalid literal for int() with base 10: 'The minimum experience required for this role is **3** years.  \\n\\n**Key Evidence:**  \\n- The requirements explicitly state: *\"3+ years of experience in a data engineering or similar role...\"*  \\n\\nN\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-berlin-60k-at-optimus-search-4180633246?position=8&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=IL0tTCvvcF578QdpHCbWbA%3D%3D\n","['XML', 'XPath', 'XSL', 'XQuery', 'NoSQL', 'SQL', 'Java', 'Python', 'HTML', 'HTTP', 'REST', 'JSON', 'Service-Oriented Architectures']\n","   \n","https://de.linkedin.com/jobs/view/junior-software-engineer-at-thryve-4187259406?position=9&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=9oz3x7Ep99NAvSSiS0F2PA%3D%3D\n","['TypeScript', 'Angular', 'Java', 'JavaScript', 'Selenium', 'Playwright', 'SQL', 'JSON', 'Git', 'Maven']\n","Error is invalid literal for int() with base 10: '**Minimum Experience Needed:** 0 years  \\n*(Note: The job description does not explicitly state a minimum number of years. It emphasizes skills, academic background, and \"demonstrated experience,\" wh\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-teksystems-4187889417?position=10&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=KqrGel63as%2Fb3%2BYM93I7KA%3D%3D\n","['SQL', 'Databricks', 'Python', 'AWS', 'Airflow', 'S3']\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-at-localstack-4179133045?position=11&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=9fefs2%2BmhBZ%2FSLTQY2JV6Q%3D%3D\n","['Python', 'AWS S3', 'AWS ECS', 'AWS Glue', 'AWS EMR', 'Relational Databases', 'Data Warehouses', 'Data Orchestration Tools', 'SQL', 'BI Tools', 'Docker', 'Real-time Data Ingestion', 'Big Data', 'Data Pipeline Development', 'Data Modeling', 'Data Lake Architecture', 'Cloud Platforms']\n","   \n","https://de.linkedin.com/jobs/view/junior-cloud-data-engineer-all-genders-at-dymatrix-4182283951?position=12&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=VCaS%2FN5xX59UN1EVN1Ug3w%3D%3D\n","['Azure Cloud', 'Data Engineering', 'Data Integration', 'Data Cleansing', 'Data Deduplication', 'DWH/Data Lake/BI Cloud Architecture', 'Big Data Platforms', 'Customer Data Platform (CDP)', 'SaaS Platforms', 'Data Infrastructure & Analytics']\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-m-w-d-at-hoyer-group-4183336123?position=13&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=WH6BugdyU6qM7S6q%2FB%2F4%2Fw%3D%3D\n","['Technical Skills: Talend', 'Snowflake', 'GitHub', 'SQL', 'Data Vault 2.0', 'ETL (Extract', 'Transform', 'Load)', 'Datenmodellierung (Data Modeling)', 'Datenbankadministration (Database Administration)', 'Performance-Tuning', 'Refactoring', 'Qlik', 'Agile Methoden (Agile Methodologies)', 'Data Warehouse Management', 'Datenextraktion (Data Extraction)', 'Versionierung (Version Control)']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-vay-4184077003?position=14&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=WuNfCbzMD46PFYSJtRAfSw%3D%3D\n","['AWS Lambda', 'AWS Step Functions', 'Apache Kafka', 'Airbyte', 'Snowflake', 'dbt', 'Protobuf', 'Apache Avro', 'JSON', 'Terraform', 'GitHub Actions', 'Grafana', 'AWS CloudWatch', 'Apache Superset', 'SQL', 'Golang', 'Python', 'AI tools', 'data modeling', 'ETL pipelines', 'API development', 'cloud infrastructure automation', 'data warehousing', 'schema evolution', 'monitoring tools', 'data integrity management']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-lawrence-harvey-4187779748?position=15&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=xhT8UdJhmDvmfIYb6qmzFA%3D%3D\n","['Snowflake', 'dbt (Data Build Tool)', 'data transformation pipelines', 'data architecture', 'data modeling', 'relational databases', 'flat files', 'big data systems', 'high-performance analytical databases', 'ERP data', 'data pipeline development', 'data orchestration', 'workflow automation', 'KPI frameworks', 'reporting frameworks.']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-azure-microsoft-fabric-m-f-d-at-repa-deutschland-4173954227?position=16&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=B4U0uIASe7SiZzXU1TJWRA%3D%3D\n","['Microsoft Fabric', 'Azure Administration', 'Azure Data Factory', 'Azure Synapse', 'SQL', 'Python', 'Git', 'ETL/ELT', 'Data Modeling (Relational', 'Dimensional', 'Lakehouse)', 'Azure Data Lake', 'Data Pipelines', 'Data Flows', 'Notebooks', 'ERP Integration', 'Data Consolidation', 'Data Transformation', 'Cost Optimization', 'Azure Security', 'Performance Troubleshooting', 'Azure Active Directory', 'Azure Storage.']\n","   \n","https://de.linkedin.com/jobs/view/mid-level-analytics-engineer-m-f-d-at-getolo-4194205148?position=17&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=i1n4%2Ff7jzSsKJw6xE9j4mg%3D%3D\n","['SQL', 'dbt (Data Build Tool)', 'Python', 'Git', 'Airflow (workflow orchestration)', 'dlt', 'Metabase', 'Cloud-based data technologies']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-irs-group-4141156208?position=18&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=t4GVnjb2n6Rkb2wwrmnmVg%3D%3D\n","['SQL', 'Snowflake', 'Redshift', 'Power BI', 'Tableau', 'SAP Integrated Suite', 'Lobster Data', 'Datenbanken', 'Data Warehouses', 'Data Modeling', 'Data Integration', 'Data Pipelines', 'ETL', 'Data Flow Diagrams', 'Technical Documentation', 'BI Systems', 'Datenvisualisierung', 'Skalierbare Datenlösungen', 'Middleware']\n","   \n","https://de.linkedin.com/jobs/view/software-engineer-confidential-computing-and-ai-at-edgeless-systems-4184195941?position=19&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=vyuW734ZOn01%2B34xPUGq0g%3D%3D\n","['Go', 'Rust', 'C++', 'AMD SEV-SNP', 'Intel TDX', 'NVIDIA H100', 'Kubernetes', 'Terraform', 'Linux', 'NixOS', 'gRPC', 'Confidential Computing', 'Cybersecurity', 'CI/CD', 'Agile Methodologies', 'Cloud Infrastructure', 'AI/GenAI', 'Supply-Chain Security', 'Containerization', 'Firmware Development', 'Kernel Development']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-smart-steel-technologies-4149489934?position=20&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=gILspQFqy7Afm8X3VOrXoQ%3D%3D\n","['Python', 'C++', 'SQL', 'PostgreSQL', 'Oracle', 'Apache Kafka', 'Kafka Connect', 'Docker', 'Swarm', 'CI/CD', 'Git', 'Data Pipeline Management', 'Query Optimization', 'Database Schema Design', 'Database Migrations', 'Stream Processing', 'Event-driven Architectures', 'Real-time Data Processing', 'Data Cleaning', 'Data Transformation', 'Monitoring Solutions', 'Troubleshooting Data Inconsistencies', 'Version Control', 'Collaborative Development Practices', 'Container Orchestration']\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-at-pricehubble-4160358445?position=21&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=pdF2AzSjDPy%2B21X%2B%2FRdxhw%3D%3D\n","['Big Data', 'Data Engineering', 'Data Pipeline Development', 'ETL', 'Data Ingestion', 'Data Transformation', 'Data Monitoring', 'Python', 'SQL', 'Geospatial Data Processing', 'PostGIS', 'GeoPandas', 'Cloud Platforms', 'Distributed Systems', 'Web Scraping', 'Version Control', 'CI/CD', 'Data Visualization', 'Data Quality Management', 'Performance Optimization', 'Scalable Systems', 'Airflow', 'Spark', 'Hadoop', 'Scrapy', 'BeautifulSoup', 'AWS', 'GCP', 'Azure', 'Grafana', 'DevOps.']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-frankfurt-cologne-stuttgart-germany-at-unit8-4184198748?position=22&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=YXM1Z3ytZzBWElOraUqgVw%3D%3D\n","['AWS', 'EKS', 'CloudFormation', 'Docker', 'Python', 'PySpark', 'Azure', 'ML Studio', 'Data Factory', 'Databricks', 'Spark', 'Java', 'C#', 'C++', 'Data Governance', 'Data Access Techniques', 'Data Storage Techniques', 'Distributed Systems', 'CI/CD', 'Data Pipelines', 'Data Quality Tools', 'Open-Source Technologies', 'Closed-Source Technologies', 'MLOps']\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-aws-at-pcg-dach-4193887059?position=23&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=4PRW%2BbWxVtJ9xZAzYD5IEQ%3D%3D\n","['Python', 'AWS', 'Data Engineering', 'Data Warehousing', 'Machine Learning (ML)', 'Artificial Intelligence (AI)', 'Data Pipelines', 'Cloud Technologies']\n","Error is invalid literal for int() with base 10: 'The minimum experience needed for this role is **0 years**. The job description emphasizes that high motivation and willingness to learn are prioritized over prior experience, making it suitable for \n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-aws-at-pcg-dach-4193881634?position=24&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=v1AXv7N4rNKkU3%2FHV9ZvWA%3D%3D\n","['Technical Skills: Python', 'AWS (Amazon Web Services)', 'Data Pipelines', 'Data Warehousing', 'Machine Learning', 'Artificial Intelligence (AI)']\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-aws-at-pcg-dach-4193885500?position=25&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=c0Yw6F0xkEj5Gn1QMfDA7w%3D%3D\n","['AWS', 'Data Engineering', 'Data Pipelines', 'Data Warehousing', 'Python', 'Machine Learning (ML)', 'Artificial Intelligence (AI)', 'Cloud Technologies']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-hirexa-solutions-4191440486?position=26&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=PAJXhoTgKXvIcOJX7urs0g%3D%3D\n","['Azure Data Factory (ADF)', 'Databricks', 'Apache Spark', 'Python', 'PySpark', 'SQL', 'Scala', 'Azure Storage', 'Azure Data Lake Storage (ADLS)', 'Azure Blob Storage', 'Delta Lake', 'Data Modeling', 'ETL', 'Star Schema', 'Slowly Changing Dimensions', 'Azure DevOps', 'CI/CD', 'Performance Optimization', 'Spark Tuning', 'Cluster Management']\n","   \n","https://de.linkedin.com/jobs/view/junior-data-analyst-at-lovehoney-group-4178790592?position=27&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=%2BRr12yjMmGn%2BjJOr2gHP0Q%3D%3D\n","['SQL', 'Python', 'BigQuery', 'Google Analytics 360', 'Data Visualization', 'Apache Airflow', 'Git', 'Data Warehousing']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-f-d-m-at-temedica-4175832536?position=28&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=JvkmEZ91GlsI8PpLvccUgA%3D%3D\n","['GCP', 'AWS', 'Azure', 'SQL', 'Python', 'dbt', 'Git', 'Terraform', 'CloudFormation', 'CI/CD pipelines', 'data engineering', 'data warehousing', 'data pipelines', 'batch processing', 'stream processing', 'data mesh architecture', 'data observability', 'Infrastructure as Code (IaC)', 'reporting frontends']\n","Error is invalid literal for int() with base 10: 'The minimum experience required for this role is **3 years** of professional experience in data engineering or data warehousing, specifically in creating and managing data pipelines.'\n","   \n","https://de.linkedin.com/jobs/view/ai-engineer-intern-at-enzo-4189988603?position=29&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=QArqSjCFbTkXICvs46H%2FdQ%3D%3D\n","['Python', 'SQL', 'TensorFlow', 'PyTorch', 'Time Series Analysis', 'Neural Network Development', 'Data Pipeline Engineering', 'Data Acquisition', 'Data Labeling', 'TypeScript', 'IoT', 'Machine Learning', 'Data Analysis', 'AI Solutions Development', 'Analytics Skills']\n","Error is invalid literal for int() with base 10: \"The minimum experience required for the role is **0 years**.  \\n\\nThis is an **entry-level internship** targeting students pursuing a bachelor's/master's degree. Key indicators:  \\n- No explicit prof\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-aws-at-pcg-dach-4193879911?position=30&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=Z90vfXlR9OGn5nYq7QX2jQ%3D%3D\n","['AWS', 'Data Pipelines', 'Data Warehousing', 'Machine Learning (ML)', 'Artificial Intelligence (AI)', 'Python', 'Cloud Technologies']\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-at-teralytics-4178771278?position=31&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=w5WYo%2FNv1LTNSVePTU8XDw%3D%3D\n","['Scala', 'Apache Spark', 'Kubernetes', 'Hadoop', 'Apache Airflow', 'Workflow Orchestration', 'Big Data Technologies', 'AWS', 'GCP', 'Azure', 'Data Science', 'Machine Learning (ML)', 'Artificial Intelligence (AI)', 'ETL Pipelines', 'Data Integration', 'Data Processing Pipelines', 'Cloud Platforms']\n","   \n","https://de.linkedin.com/jobs/view/embedded-software-engineer-at-xpertdirect-4184433582?position=32&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=1KpqB%2FwUoBAy582KZM4Irg%3D%3D\n","['C', 'C++', 'Assembly', 'RTOS', 'AUTOSAR', 'CAN', 'LIN', 'FlexRay', 'Ethernet', 'Microcontrollers', 'SoCs', 'Oscilloscopes', 'Logic Analyzers', 'JTAG', 'Secure Firmware Development', 'Cryptographic Implementations', 'ISO 26262', 'ASPICE', 'MISRA C', 'Functional Safety', 'Cybersecurity', 'Machine Learning', 'AI', 'OTA Updates', 'Cloud Connectivity', 'ADAS', 'Powertrain Control', 'Vehicle Networking', 'Real-Time Systems', 'Hardware Integration', 'Automotive Embedded Systems']\n","Error is invalid literal for int() with base 10: 'The job description does not explicitly state the number of years of experience required. While implied skills (e.g., AUTOSAR, RTOS, functional safety) typically align with mid-level experience, **wi\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-data-ai-team-europe-remote-at-webpros-4187014866?position=33&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=D6v7pcQSMwD0YnBxFQCUrA%3D%3D\n","['Python', 'SQL', 'Google Cloud Platform (GCP)', 'AWS', 'ETL', 'Data Pipelines', 'Data Modeling', 'Google BigQuery', 'Cloud Functions', 'Bash', 'Google Dataflow', 'Apache Airflow', 'Google Dataform', 'Looker Studio', 'GitHub', 'CI/CD', 'Test-Driven Development (TDD)', 'Data Quality Monitoring', 'Data Orchestration']\n","Error is invalid literal for int() with base 10: 'The job description emphasizes the need for \"strong experience\" in key areas like ETL, Python, SQL, and cloud platforms, while explicitly excluding entry-level candidates seeking mentorship. Though n\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-m-f-d-at-retailmediatools-4178160723?position=34&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=lMFyxw7ZHhRd7GqVKhGN4A%3D%3D\n","['It seems there was an issue accessing the job description. Could you please check the following:  \\n1. Ensure the job description text is properly provided or pasted.  \\n2. Verify the link (if used) is valid and accessible.  \\n\\nOnce shared', 'I’ll extract the technical skills for you! Let me know if you need help. 😊']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-diehl-defence-4165441518?position=35&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=Rd5lJJj%2BdCh2c6ScFvXTfQ%3D%3D\n","['data management', 'data-driven applications', 'project management', 'KPI development', 'data science', 'generative AI', 'Python', 'Java', 'Scala', 'SQL', 'SAP', 'BI tools', 'MS Office']\n","Error is invalid literal for int() with base 10: 'The job description specifies \"direkteinstieg - mit berufserfahrung\" (direct entry with professional experience), which typically implies at least **1 year of professional experience** post-study. Th\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-m-w-d-at-ergon-datenprojekte-gmbh-4194918192?position=36&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=BksM3Q0mMgmAaale1sEUGw%3D%3D\n","['Azure Cloud', 'ETL', 'Azure Data Factory (ADF)', 'Data Lake', 'Data Warehouse', 'Talend', 'SSIS', 'SQL', 'C#', 'Java', 'Python', 'Microsoft Certifications', 'Azure Data Engineer Associate']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-mam-gruppe-4139026004?position=37&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=JW1Wv6wXv1GyqNSD%2Ff9yZA%3D%3D\n","['Data Architecture', 'ETL Processes', 'Python', 'SQL', 'AWS Glue', 'AWS S3', 'AWS Redshift', 'Snowflake', 'Data Vault Methodology', 'Real-Time Data Processing', 'Modern Data Pipelines', 'Data Warehouse Design', 'AWS (Cloud Services)', 'Data Catalog Management', 'Process Automation', 'Scalable Data Modeling']\n","Error is invalid literal for int() with base 10: 'The minimum experience required for this Senior Data Engineer role is implicitly **5+ years**, inferred from terms like \"seasoned,\" \"senior,\" and \"proven experience in data architecture.\" Senior role\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-diehl-defence-4104337672?position=38&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=rrSo4vPdAOYEU%2BQ%2FieNLSg%3D%3D\n","['Data Architecture', 'Data Lakes', 'Data Warehouses', 'PostgreSQL', 'MS-SQL', 'ETL Pipelines', 'Data Integration', 'Data Processing', 'Data Quality', 'Data Security', 'Data Integrity', 'Regulatory Compliance', 'On-Premise Environments', 'Python', 'SQL', 'Java', 'Scala', 'ETL Tools']\n","Error is invalid literal for int() with base 10: 'The minimum experience required for this role is **2 years**. \\n\\n**Key Evidence from the Job Description:**\\n- Explicit requirement: \"mehrjährige Berufserfahrung als Data Engineer\" (several years of\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-azure-microsoft-fabric-m-f-d-at-repa-4186540780?position=39&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=o8FHq%2F%2FltcWqqIWdozvDIg%3D%3D\n","['Microsoft Fabric', 'Azure Administration', 'Azure Data Factory', 'Azure Synapse Analytics', 'SQL', 'Python', 'ETL/ELT Pipelines', 'Data Modeling (Relational', 'Dimensional', 'Lakehouse)', 'Azure Data Lake', 'Git', 'Data Integration', 'Azure Storage', 'Azure Virtual Machines (VMs)', 'Azure Active Directory', 'Data Consolidation', 'Data Integrity', 'Performance Optimization', 'Troubleshooting', 'Notebooks', 'Version Control', 'ERP Systems Integration']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-%E2%80%93-zeitreihenanalyse-und-fehleridentifikation-at-harvey-nash-4185480833?position=40&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=EsYvxKuZAdsmP6rSuJ%2BkBQ%3D%3D\n","['ETL Pipelines', 'Python', 'PySpark', 'Power BI', 'Databricks', 'Machine Learning', 'Microsoft Azure', 'Test-Driven Software Development', 'CAN Protocol', 'ePowertrain', 'Automotive Software Development', 'Fuel Cell Development', 'Zeitreihendatenanalyse (Time Series Analysis)', 'Datenvisualisierung (Data Visualization)', 'Cloud-Dienste (Cloud Services)', 'Signalinterpretation (Signal Interpretation)', 'Testgetriebene Entwicklung (Test-Driven Development)', 'Fehleridentifikation (Error Identification)']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-cavendish-professionals-4186263558?position=41&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=b0OK6Hru7dcJER1OGGuyFg%3D%3D\n","['ETL Pipeline Development', 'Python', 'PostgreSQL', 'PostGIS', 'AWS', 'Cloud Services', 'Database Systems', 'Data Infrastructure', 'Data Processing', 'Data Quality', 'Workflow Orchestration']\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-at-initions-3837971612?position=42&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=eke1QQfxNy7kJU9V5nwmBA%3D%3D\n","['Data Analytics', 'Cloud Solutions', 'Big Data Platforms', 'Microsoft Azure', 'Databricks', 'Snowflake', 'ETL/ELT', 'Data Pipelines', 'Database Architecture', 'IT Infrastructure', 'Security Concepts', 'Data Modeling', 'Dashboard Creation', 'Artificial Intelligence (AI)', 'Machine Learning', 'Data Warehousing', 'Business Intelligence (BI)', 'IoT', 'Data Lake', 'Self-Service BI', 'Cloud Data Platforms']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-infomotion-gmbh-4189404805?position=43&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=R2N0mqmxMHU%2BqNNxmhOUxQ%3D%3D\n","['AWS', 'Azure', 'GCP', 'Snowflake', 'Data Warehousing', 'Data Lake', 'Data Lakehouse', 'Cloud Data Platforms', 'Data Vault 2.0', 'Data Management', 'Data Architecture', 'Cloud Datenplattformen', 'Datenmanagement', 'Data Modeling', 'Cloud Consulting', 'IT Consulting', 'Projektleitung', 'Systementwicklung', 'Cloud Implementation']\n","   \n","https://de.linkedin.com/jobs/view/junior-cloud-data-engineer-all-genders-at-dymatrix-4165089201?position=44&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=paEHKF6mQHRz3w%2F91awQzw%3D%3D\n","['Data Engineering', 'Customer Data Platform (CDP)', 'Data Integration', 'Data Enrichment', 'Data Cleansing', 'Microsoft Azure', 'Data Warehouse (DWH)', 'Data Lake', 'BI Cloud Architecture', 'Big Data Platforms', 'SaaS Development', 'Azure Cloud', 'Data Deduplication', 'Cloud Architecture', 'Marketing Automation', 'Customer Experience Platforms.']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-w-d-at-diehl-defence-4104336921?position=45&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=%2Bbd93cIUhnRzEOBv3YmgeQ%3D%3D\n","['Data Architecture', 'Data Lakes', 'Data Warehouses', 'PostgreSQL', 'MS-SQL', 'ETL Pipelines', 'ETL Tools', 'Python', 'SQL', 'Java', 'Scala', 'On-Premise Environments']\n","   \n","https://de.linkedin.com/jobs/view/powerbi-data-engineer-d-m-w-at-the-formula-consulting-4174435603?position=46&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=K0QP8%2FNvgkDw4H8uVfFbPQ%3D%3D\n","['Power BI', 'SQL', 'Spark', 'Python', 'Azure Data Factory', 'ETL/ELT processes', 'MS Fabric', 'Star Schema']\n","Error is invalid literal for int() with base 10: 'The minimum experience required for this role is **2 years**. This includes at least 2 years of professional experience in Power BI (backend) and Azure Data Factory, as well as 2 years of full-time w\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-w-m-d-at-crewmeister-4159097559?position=47&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=cDJBZavRtstvgNBl5wjd1w%3D%3D\n","['Data Warehousing', 'ETL Development', 'Data Modeling', 'Schema Design', 'Google BigQuery', 'Python', 'SQL', 'BI Tools (Google Looker Studio)', 'Predictive Modeling', 'Time Series Analysis', 'Customer Behavior Analysis', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'API Integration', 'Web Services Integration', 'Data Pipeline Management', 'Dashboard Development', 'KPI Tracking', 'SaaS Environments', 'Third-Party Application Integration']\n","   \n","https://de.linkedin.com/jobs/view/junior-data-engineer-m-w-d-at-initions-3837973874?position=48&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=mcNZrBSVlPIFYFDCS2o%2BZQ%3D%3D\n","['Microsoft Azure', 'Databricks', 'Snowflake', 'SQL', 'Python', 'Apache Spark', 'ETL/ELT', 'Data Pipelines', 'Database Architectures', 'Data Modeling', 'Cloud Infrastructure', 'IT Security', 'Power BI', 'DevOps', 'Data Analysis', 'Machine Learning', 'Artificial Intelligence', 'Big Data Platforms', 'IoT', 'Data Lake', 'Business Intelligence', 'Data Warehousing']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-bi-developer-m-w-d-at-eco-schulte-gmbh-co-kg-4185674563?position=49&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=YQ7C0iItMral6sfGQHpnuw%3D%3D\n","['QlikView', 'Qlik Sense', 'SQL', 'Python', 'ETL', 'Data Warehousing', 'Data Pipelines', 'API Development', 'Reporting', 'Business Intelligence', 'Automation', 'Database Structures']\n","   \n","https://de.linkedin.com/jobs/view/python-software-engineer-at-unique-4174817695?position=50&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=ZsXGc3LKywCW49IaWj2BUw%3D%3D\n","['Python', 'scalable architectures', 'AI applications', 'SDK development', 'toolkit development', 'design patterns', 'cloud services', 'CI/CD pipelines', 'GitHub workflows', 'containerization', 'Docker', 'MLOps', 'DevOps']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-at-carbonfuture-4187294641?position=51&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=uPNVRdtKufVf8j7yhjE6xw%3D%3D\n","['SQL', 'Python', 'Power BI', 'dbt (Data Build Tool)', 'Microsoft Azure', 'data warehouse integration', 'data transformations', 'data quality monitoring', 'database optimization', 'data infrastructure roadmap development', 'data visualization tools']\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-at-payla-4189401753?position=52&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=xakwvI9dYcIQXzLJ%2BH8dtg%3D%3D\n","['Python', 'Spark', 'Polars', 'Dagster', 'Databricks', 'DeltaLake', 'SQL', 'Data Modeling', 'ETL', 'Data Warehousing', 'Containers', 'CI/CD', 'Apache Airflow', 'AWS', 'Kubernetes', 'DevOps', 'Apache Superset', 'Looker', 'Tableau']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-f-m-x-at-vollcom-digital-3975240350?position=53&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=rclaPoOE19Y9jeo6DI7dIg%3D%3D\n","['Python', 'Java', 'Scala', 'SQL', 'RDBMS', 'NoSQL databases', 'AWS', 'Google Cloud Platform', 'Azure', 'ETL tools and processes', 'data pipelines', 'data ingestion', 'data integration', 'data processing', 'data validation', 'data cleaning', 'data governance', 'data security']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-junior-at-reeeliance-4182911706?position=54&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=0PzfqAxmKqK%2FNv%2FWB9gKSg%3D%3D\n","['SQL', 'Python', 'Matillion', 'Vaultspeed', 'Snowflake', 'Azure Synapse', 'Azure DevOps', 'GitLab', 'Data Modeling', 'Data Warehousing', 'ETL', 'Cloud Platforms (AWS', 'Azure)', 'Data Pipeline Orchestration', 'Data Quality Assurance', 'Agile Methodologies', 'DevOps', 'Version Control']\n","Error is invalid literal for int() with base 10: 'The job description specifies that the role is categorized as \"Berufseinstieg\" (Entry Level) and does not explicitly mention a minimum number of years of experience. While it emphasizes technical ski\n","   \n","https://de.linkedin.com/jobs/view/senior-data-engineer-m-w-d-data-analytics-deutschland-at-colliers-4175115658?position=55&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=3f1t9tTzf%2FN%2FIXSaTVHyOQ%3D%3D\n","['C#', 'Datenpipelines', 'ETL', 'APIs', 'Azure Data Factory', 'Azure Synapse Analytics', 'Azure Data Lake Storage', 'Azure Databricks', 'Relationale Datenmodelle', 'SQL', 'Code Review', 'ML-Modellintegration', 'Dateninfrastruktur', 'API-Entwurf', 'Azure-Dienste', 'Datenanalyse', 'Datenintegrität']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-f-m-d-full-time-remote-at-credium-4151194669?position=56&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=nxbXB5RrXZ6%2FWStlWjeP8Q%3D%3D\n","['Azure Cloud', 'ETL Pipelines', 'Python', 'pandas', 'numpy', 'dask', 'PySpark', 'RDBMS', 'PostgreSQL', 'Oracle', 'MSSQL', 'Data Warehousing', 'Data Architecture', 'Data Modeling', 'Data Mapping', 'Data Lineage', 'Data Quality', 'Geospatial Data', 'PostGIS', 'QGIS', 'Apache Sedona']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-w-m-d-at-weptech-elektronik-gmbh-4194566066?position=57&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=jVeon37WUtwYWXMoYkL%2BJQ%3D%3D\n","['ETL', 'SQL', 'Data Integration', 'Data Pipelines', 'Batch Processing', 'Streaming Data', 'Data Cleansing', 'Data Validation', 'Data Monitoring', 'Data Platform Development', 'BI Tools', 'Data Formats', 'Data Architecture', 'Automation', 'Database Technologies', 'Data Quality', 'ETL Tools']\n","   \n","https://de.linkedin.com/jobs/view/data-engineer-m-f-d-at-kinexon-4189813490?position=58&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=gR42y%2FrIRzytpvoA47rvgg%3D%3D\n","['Python', 'C++', 'Data Analysis', 'Machine Learning', 'Real-time Data Processing', 'Sensor Data Processing (GPS', 'LPS', 'IMU)', 'Cloud Computing', 'CI/CD (GitLab)', 'Build Systems (CMake', 'Conan)', 'Algorithm Development', 'Debugging', 'Software Optimization', 'Scientific Computing (Python libraries)', 'IoT', 'Data Pipelines', 'Event Detection', 'Signal Processing', 'Documentation', 'Software Testing', 'Cross-functional Collaboration', 'Problem-solving', 'Embedded Systems', 'Performance Metrics Design']\n","   \n","https://de.linkedin.com/jobs/view/data-analyst-bi-analyst-data-engineer-m-w-d-german-c1-c2-required-at-the-adecco-group-4139855735?position=59&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=1pLYm%2BBqMDDk7p8HOD6B7A%3D%3D\n","['SQL', 'Python', 'R', 'Power BI', 'Tableau', 'Looker', 'AWS', 'Azure', 'Google Cloud Platform (GCP)', 'ETL', 'Data Warehousing', 'Databases', 'Data Pipelines', 'Data Modeling', 'Data Analytics Tools', 'Data Quality Management', 'BI Dashboards']\n","   \n","https://de.linkedin.com/jobs/view/analytics-engineer-m-f-d-at-raisin-4179415486?position=60&pageNum=0&refId=aE0yioxQ%2BXQs61%2Fsv4y9OA%3D%3D&trackingId=W3iohW9VZdettW6p%2BQCA1A%3D%3D\n","['']\n","Data engineer jobs: 60\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vzbz6bSSAFmE"},"execution_count":null,"outputs":[]}]}
